{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cdc1855e",
   "metadata": {},
   "source": [
    "# Entrenamiento de un Modelo de Clasificación\n",
    "\n",
    "En este notebook entrenamos un modelo de clasificación para predecir si un tumor es maligno o benigno usando el dataset procesado.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c4be6e5",
   "metadata": {},
   "source": [
    "## 1. Importar librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5179d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.set_theme(style=\"whitegrid\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45f424b9",
   "metadata": {},
   "source": [
    "## 2. Cargar el dataset procesado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c1e084f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ruta_procesado = Path(\"../data/processed/cancer_mama_procesado.csv\")\n",
    "\n",
    "if not ruta_procesado.exists():\n",
    "    raise FileNotFoundError(f\"No se encontró el archivo procesado en: {ruta_procesado.resolve()}\")\n",
    "\n",
    "df = pd.read_csv(ruta_procesado)\n",
    "print(\"Datos procesados cargados correctamente\")\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f704d28",
   "metadata": {},
   "source": [
    "## 3. Definir variables predictoras (X) y objetivo (y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4432534",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = list(df.columns[1:11])\n",
    "\n",
    "X = df[feature_cols]\n",
    "y = df[\"diagnosis_binaria\"]\n",
    "\n",
    "print(\"Dimensiones de X:\", X.shape)\n",
    "print(\"Dimensiones de y:\", y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80ee8f9c",
   "metadata": {},
   "source": [
    "## 4. Separar en train y test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbd4e24f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(\"Tamaño de train:\", X_train.shape[0])\n",
    "print(\"Tamaño de test:\", X_test.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de784a9d",
   "metadata": {},
   "source": [
    "## 5. Crear un pipeline con escalado + Regresión Logística"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6276b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(\n",
    "    steps=[\n",
    "        (\"escalador\", StandardScaler()),\n",
    "        (\"modelo\", LogisticRegression(max_iter=1000))\n",
    "    ]\n",
    ")\n",
    "\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "print(\"Modelo entrenado correctamente\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ae1ecff",
   "metadata": {},
   "source": [
    "## 6. Evaluación del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c6a5ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "print(\"Matriz de confusión:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "print(\"\\nReporte de clasificación:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "985e4b28",
   "metadata": {},
   "source": [
    "### Visualización de la matriz de confusión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f66f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "plt.figure(figsize=(4,4))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "plt.xlabel(\"Predicción\")\n",
    "plt.ylabel(\"Valor real\")\n",
    "plt.title(\"Matriz de confusión\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7831e106",
   "metadata": {},
   "source": [
    "## 7. Comentarios finales\n",
    "\n",
    "- Revisar si el modelo se comporta de forma equilibrada entre clases.\n",
    "- Identificar si existen problemas de desbalance.\n",
    "- Proponer posibles mejoras:\n",
    "  - Probar otros modelos (Random Forest, SVM, etc.).\n",
    "  - Ajustar hiperparámetros.\n",
    "  - Realizar validación cruzada.\n",
    "\n",
    "Este notebook sirve como base para explicar cómo evaluar un modelo de clasificación en un contexto de Ciencia de Datos."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
